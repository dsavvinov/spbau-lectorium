############################## Лекция 5.04 ################################################

[| var |] = [LD var]
[| x + y |] = [| x |] ++ [| y |] ++ [ ADD ]
[| num |] = [ IMM num ]

cons
car
cdr
Такие названия для операций над списками позаимствованы из какой-то реализации

На haskell:
Стек - список значений алгебраического типа, который объединяет все занчения в программе

C:
Гораздо лучше, если в стеке будут храниться тупо указатели 

Например в джаве нет понятия bool на уровне вирутальной машины
Там тупо инт

НАм нужна область в памяти чтобы хранить замыкания

Когда мы говорим о реализации машины SECD возникает вопрос управления памятью
Как мы справились с этой проблемой в миниМЛ? Мы тупо выкидывали объек из стека.
По хорошему надо очишать память, а то программа может упасть. Правда мы не упадём, потому что рантайм хаскеля всё сделает.

Проще говоря там есть сборщик мусора.  

Doug - Lee allocator

Как теперь освобождать память?
Нам нужны объекты, про которые мы точно знаем, что они живвые. А дальше по индкукции. Ну ясен пень, такие объекты надо взять на стеке.
Потому то мы всегда может туда обратиться. Содержимое регистров процессора тоже должны быть живыми объектами, то же самое про каукую-нибудь
рабочуу облать . Вся эта хрень вместе называется корневым набором root set.
	
	Теперь идём по графу от root set. Но как теперь понять, что это указатели а не число? В реальных языках программирования мы можем их 
отлиить хотя бы потому, что мы знаем тип каждого поля и объекта, и знаем, как компилятор отображает их в ячейки памяти.
Некотороы системы вообще испольлзую типизированны инструкции, например Java. В языке вроде С с этим всё плохо. Там главны GC наз-ся Boehm GC
Нам критично просрать указатель, поэтому если я не могу доказать, что нечто является указателем, то я соответсвуюший объект считаю указателем.
 
Как найти неживые объекты? считать все дохлые неудобно. Обычно наоборот ищут живые
Есть несколько подходов: 
	подсчёт ссылок, храним в объекте количество ссылок. Когда добавляю указатель: ссылок +1, стираю -1. Только таким методом ты не удалишь острова
в памяти. Зато его изи-пизи реализовывать. 

В следущий раз будет Mark & Sweep и Copying GC.

Задача: написать реализацию, которая позволяла бы объявлять функции отдельно.
https://bitbucket.org/dtim/fpli/
Можно взять любую версию miniML. 

############################## Лекция 14.04 ################################################

recap: я прослушал recap
как выделять?
как осовобождать?

Выделение памяти
	1) сдвиг указателя
		+ двигать легко(легко выделять)
		- трудно освобождать, фрагментация
		более страшно внешняя фрагментация

	2) список свободных блоков
		+ освобождать изи
		+ но зато можем записывать малленькие куски на место удалённых
		- более долгое выделение, тоже фрагментация
		более страшно внутрення фрагментация

	Фрагментация:
		Внешняя
			нет блока нужного размерера лежащего подряд в памяти
		Внутренняя
			блоки будут заполнены не полностью, так мы теряем память, которую не освободить в принципе

	Итог: фрагментация это боль

Я не знаю, как мы сюда забралить, но говорим, что лисп зашибись, основаная структура данных в LISPe это пара [ | ] cons cell
Вообще мы начали с того, что для языка программирования мы обычно выделяем память под структуры типичного размера
Если бы будет ориентироваться на такие блоки, то внешняя фрагментация нам не страшна, потому что обычно выделяются и освобождаются не большие, а маленькие объекты.

Теперь про освобождение.
Как узнать что блок больше не потребуется?
Как освобождать?
Как решить проблему фрагментации? Память же заканчивается.

Допустим нам надо освободить 1000 странци памяти. Освободим всё сразу? Или освободим потом? 1 раз на 5 секунд или 5 раз по 1 секунде? На самом деле это зависит от системы, с которой мы работаем.

Мы говорим, что "stop-the-world" остановка при сборке мусора это плохо, поэтому мы страраемся делать в фоновом режиме или на отдлеьном процессоре. И мы не должны оказать в такой ситуации, что не можем выделить память тупо потому, что сборщик мусора ещё не освободил нам памяти.

Когда вообще запускать сборку мусора.
	Когда закончится
	Запускать параллельно
	~По расписанию
	~Когда программисто попросит

Какие виды сборщика мусора у нас есть?
	Сам программист C/C++.
		В функциональных языках это был бы адок, потому что у нас нет какой-то явной операции выделения памяти.
	Автоматически

Сборщики мусора появились дофига давно. Первый раз в LISPe, потому что это был первый функциональный язык

Какие способы мониторина памяти у нас есть?
	Подсчёт ссылок (Reference counting)
		x = y
			y.refs++
			x.refs--    <- вот эта хрень рекурсивная и может привести к удалению целого каскада объектов
						   но мы не знаем, сколько времени это займёт, следовательно не знаем, сколько работает присваивание
			if (x.refs == 0)
				release(x)
			x = y

		Obj a = new A()
		a = a

		Ленивое освобождение памяти
			Заводим список освобождаемых объектов. Вместо удаления кладём туда. В таком списке живут указатели на объекты, которые были один раз освобождены. Наличие объекта в этом списке не увеличивает количество ссылок на него

		Меня задолбало: на вики описано лучше 

			Если есть циклы. 
				Можем запускать алгоритм поиска циклов
				Делим объекты на группы, так, чтобы любой цикл был ровно в одно группе. Мы не удаляем обекты, пока вся группа не станет свободной, а потом удаляем всю группу целиком. Единственная проблема, понять, как делить оюъекты на группы.

		Можем хранить счётчики ссылок в отдельной таблице. Что более эффективно как при совместном доступе, так и благодаря локальности. 

	Mark & Sweep
		Идея:
			1) Помечаем объекты, какой из них живой
			2) Удаляем все неживые объекты

		Строим граф достижимых объектов, стартуя со стека

		Идея трёхцветной раскраски:
			В начале белый : unvisited,
			Черный : проанализировали его и всех потомков (procees)
			Серый : visited 

			В конце надо будет удалить все белые объекты

			! Никогда чёрный объект не может ссылаться на белый
			Объект жив, если входит в транзитивное замыкание отношения достижимости из корня

			На следующей итерации тупо меняем черный и белые цвета местами

	~ во времена Lisp-2
	История: PLANNER, CONNINER - языки на коленке
	SCHEME

	Копирующий сборщик мусора
		Гоняем по живым объекам в памяти и копируем их упакованно. Если в прцоцессе копирования рекурсивно натыкаемся на уже скорпирванный алгоритмом объект, то тупо переставляем указатель. Ещё важно учеть что надо хранить в объекте указатель на новое расположение внутренним полем, чтобы сслыающиеся на него чуваки смотрели на корректное поле.

		Циклические объекты
			Ноу проблем

		Фишка в том, что нам меньше обходить чем в M & S, Потому что мы ходим только по живым объектам, а в sweep надо пройти по всем объектам. НО нам надо копировать в процессе, что дольше. 
		В sweep конечно освобождаем нахаляву, зато тут мы упаковываем и устраняем фрагментацию. 

		Правда нужно больше памяти. Сначала левая половина для выделения памяти, правая - для копирования. Потом наоборот.
		Если добиться правильного порядка обхода, то объекты и вложенные объекты будут лежать рядом в памяти, тем самым повышая локальность.

		Алгоритм Mark Compact - это как M&S. Ходим как в mark, и храним карту, где лежат живые объекты. Тепер можем идти по живым обектам одним указателем и по свободному месту другим. При переносе указателя поступаем так же как раньше, чтобы внешние ссылки были корректны. 

		Что-то Тимофеев пиздит. Засомневался тут. Лучше потом перепроверить. 

	Ещё какой-то сборщик, но Т забыл название.
		[xxxxxx|                ]
		Делаем Mark-Compact не для всей памяти, а какого-то фрагмента

	Generation GC
		Две гипотезы поколений:
			Время жизни объекта пропорционально возрасту <- оказалось говно
			Более слабая: большая часть объектов умирают молодыми <- норм

		Идея: поделим кучу на несколько частей: молодое и старое поколение
		[  yoing |  old  ]
		В молодое помещаем объекты, которые вновь создаются

		Молодых трогаем почаще, используем копирующий сборщик мусора. Т.к. объекты мелки, то копировать мало.  
		Старных трогеам пореже, там реализиуем что-нибудь типа M&S или Mark Compact и будем делать значительно реже.

		Пацаны из зала говорят, что есть вторая гипотеза: объекты из старого поколения редко ссылаются на объекты их нового.


######### Позже в тот же день. Практика. #################

let/letrec
where

let x = y in z ~ (\x.z) y
letrec x = y in z ~ let x = Y(\x.y) in z ~ (\x.z)(Y(\x.y))

let x = x in x + 1 ~ (\x.x+1)x -> x + 1
letrec x = x in x + 1 ~ let x = Y(\x.x) in x + 1 
                      ~ (\x.x+1) (Y(\a.a)) -> + (Y(\a.a)) 1
Где + (Y(\a.a)) 1 ~ (\a.a)(Y(\a.a)) ~ Y(\a.a) нормальной формы нет, undefined

В интерпретаторе 
	eval [] (Rec ("x", EVar "x", ESum (EVar "x", EInt 1))) ;;
	eval [("x", 100)] (Rec ("x", EVar "x", ESum (EVar "x", EInt 1))) ;;

	// Тут нет зацикливания
	eval [] (ERec ("x", EVar "x", ESum (EVar "x", EInt 1))) ;;

Мы можем считать это базовой конструкцией языка и реализоваывать в интерпретаторе, либо в самом языке, но тогда придётся ввести комбинатор неподвижной точки. Говорят, это не круто потому что черех fix-комбинатор получится не очень эффективное решение, т.к. комбинатор надо таскать за собой и как-то оптимизировать, который ещё хрен заоптимизируешь. С комбинатором ещё геморрой с проверкой типов.

Зачем нам let и letrec сразу? letrec же можнее. Ответ: в принципе, для удобства.
Например:
	// такая конструкция для letrec была бы некорректна, а для let норм
	// вопрос лишь в том, разрешить ли программистам так писать
	let x = something in let x = preprocess (x) in ....x
-------------
f x = x + g(y)  | letrec
g x = x - 1     |     f = \x.x + g y
main = f (g 5)  |     g = \x.x - 1
                |     main = f (g 5)
                | in main

На Камле так писать нельзяЮ т.к. нужен let вначале
Справа записан каноноческий способ транслирвать такие конструкции

Как реализовать такую консрукцию, чтобы всё обхединить в один letrec
letrec fgs =
	(\x.x + (snd fgs) y
	, \x.x - 1)
in ...

Ещё как-то через Y-комбинатор, но я не понял

В letrec при вычислении добавляются все имена одновременно, потому что там функции могут ссылать друг на друга
Чит: можем порядок действий фиксироват с помощью let, если у нас нет нормальног порядка рекурсии. Так, например, сделано в F#

Го запилим ещё и case:

case E of
	p1 -> e1
	p2 -> e2
	...
	pn -> en
	_ -> fail

Давайте договоримся, как мы будем вычислять такое выражение? До какой степени будет вычислять E? В строгом языке до нормальной формы, в хацкеле - до слабой говолной нормальной формы. 

Нужно договорить о том, что такое паттерн
...

Будем вычислять E до той степени, чтобы поянть удовляетвоярет E образцу или нет
Договариваемся матчить сверху вниз

Мы можем несколько оптимировать матчин, уже посмотрев на образец
Помним о возможности того, что выражение может не иметь нормальной формы

Пример:
length (Cons 1(Cons 2 Nil)) = 5

Если мы хотим представлять конструкции в чистом лямбда-исчислении возникают два вопроса:
   что делать с типами?
   как это всё представлять?

	На уровне проверки типов ввести механизм контекстов
	listInt[Nil]
	listInt[Cons|  |  ]
                 |  |
                 v  v
    Ничто не мешает сделать для этого ещё один тип данных
    data Tril a = Lin | Snoc (Tril) a

	tag[Lin]
	tag[Sonc|  |  ]
             |  |
             v  v

	Хотим, чтобы такие штуки в памяит были взаимозаменяемы:
	или вешаем тэги, или протягиваем проверку типво в рантайм

	Фишка в том, что мы не ссаный C и перехватываем в рантайме все некооректные приведения. А в C память состояла тупо из байтиков, они были все одинаковы и мы могли интерпретировать их как нам угодно.

	Гаранитю того, что всё сходится мы можем обеспечивать по разному:
	1) позволять всё что угодно на этапе компиляции и перехватывать в рантайме
	2) пресекать всё зло проверкой типов ещё на этапу компиляции
	3) В F# мы например делаем проверку статически и типы оставляем. У остальных ребять присутсвует стирание типов.

Итак, что мы хотим в нашем языке?
	lambda-абстракции
	константы
	примитивные операции
	let
	letrec
	case
	делаем конструктор примитивной операцией ???

Анонс: 
	сделаем такой язык
	реализуем его с помощью метода редкуции графов
	G-machine, STG - spineless tagless g-machine
	сможет потом нормально копать в компиляторе хаскеля, потому что базовую машину будем знать